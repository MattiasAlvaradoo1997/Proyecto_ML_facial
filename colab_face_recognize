# -*- coding: utf-8 -*-
"""Proyecto_Semestral_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1at15vga5FC2LWIMLllzK0SQeeBuw5R6p
"""

# SI ARROJA ERROR POR shape_predictor_68_face_landmarks.dat.bz2, DESCOMENTAR LO DE ABAJO

# !wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
# !bunzip2 "shape_predictor_68_face_landmarks.dat.bz2"

from google.colab import drive
drive.mount('/content/drive')

# NOMENCLATURA DE REDES

age_netn     = [119, 118, 118, 120]
gender_netn  = [119, 80, 80, 2]
lr_gender    = 0.0004
lr_age       = 0.0004
epoch_gender = 10000
batch_gender = 90
epoch_age    = 10000
batch_age    = 90

import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import numpy as np
import glob
import dlib
import cv2
import io

from google.colab import output
from google.colab import files
from IPython.display import Image, display
from tensorflow import keras
from tensorflow.keras import layers
from keras.utils import np_utils
from keras.layers import Dense
from keras.models import Sequential
from keras.optimizers import SGD
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from google.colab.patches import cv2_imshow
from keras.models import load_model

"""**Función para leer rostros y designarles landmarks**"""

# Función para leer imagen DE UNA CARA Y DE FRENTE

def read_data(data, image=False, points=False):

  cv_img = np.array([])
  detector = dlib.get_frontal_face_detector()
  predictor= dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")

  img = cv2.imread(data)

  gray = cv2.cvtColor(src=img, code=cv2.COLOR_BGR2GRAY)

  faces = detector(gray)
  
  

  for face in faces:
    x1 = face.left()
    y1 = face.top()
    x2 = face.right()
    y2 = face.bottom()

    landmarks = predictor(image=gray, box=face)

    for n in range(0, 68):
      x_y = np.array([landmarks.part(n).x,
                      landmarks.part(n).y])

      cv_img = np.concatenate((cv_img, x_y), axis=0)
      if (points):
        cv2.circle(img=img, center=(x_y[0],x_y[1]), radius=2, color=(0,255,2), thickness=-1)
  
  if len(cv_img) == 136:
    cv_img = cv_img.reshape(68,2)
    scale  = np.array([cv_img[:,0].max()-cv_img[:,0].min(),cv_img[:,1].max()-cv_img[:,1].min()]) # Vector de alto y ancho de una cara: array([alto, ancho])

    # Para que el tamaño de la cara no influya, los puntos deben comprimirse hasta caber en un cuadrado de 1x1
    for x in cv_img:  
      x[0] /= (scale.max())*1.0
      x[1] /= (scale.max())*1.0
                                    
    # Array de distancias entre puntos
    dist_array = [np.linalg.norm(cv_img[0] - cv_img[1]),np.linalg.norm(cv_img[0] - cv_img[17]),np.linalg.norm(cv_img[0] - cv_img[36]),np.linalg.norm(cv_img[1] - cv_img[2]),np.linalg.norm(cv_img[1] - cv_img[36]),np.linalg.norm(cv_img[2] - cv_img[3]),np.linalg.norm(cv_img[2] - cv_img[41]),np.linalg.norm(cv_img[3] - cv_img[4]),np.linalg.norm(cv_img[3] - cv_img[31]),np.linalg.norm(cv_img[3] - cv_img[40]),                  #10
                          np.linalg.norm(cv_img[4] - cv_img[5]),np.linalg.norm(cv_img[4] - cv_img[48]),np.linalg.norm(cv_img[5] - cv_img[6]),np.linalg.norm(cv_img[5] - cv_img[59]),np.linalg.norm(cv_img[6] - cv_img[7]),np.linalg.norm(cv_img[7] - cv_img[8]),np.linalg.norm(cv_img[7] - cv_img[57]),np.linalg.norm(cv_img[7] - cv_img[59]),np.linalg.norm(cv_img[8] - cv_img[9]),np.linalg.norm(cv_img[8] - cv_img[57]),                    #20 
                          np.linalg.norm(cv_img[9] - cv_img[10]),np.linalg.norm(cv_img[9] - cv_img[55]),np.linalg.norm(cv_img[9] - cv_img[57]),np.linalg.norm(cv_img[10] - cv_img[11]),np.linalg.norm(cv_img[11] - cv_img[12]),np.linalg.norm(cv_img[11] - cv_img[55]),np.linalg.norm(cv_img[12] - cv_img[13]),np.linalg.norm(cv_img[12] - cv_img[54]),np.linalg.norm(cv_img[13] - cv_img[14]),np.linalg.norm(cv_img[13] - cv_img[35]),        #30
                          np.linalg.norm(cv_img[13] - cv_img[47]),np.linalg.norm(cv_img[14] - cv_img[15]),np.linalg.norm(cv_img[14] - cv_img[46]),np.linalg.norm(cv_img[15] - cv_img[16]),np.linalg.norm(cv_img[15] - cv_img[45]),np.linalg.norm(cv_img[16] - cv_img[26]),np.linalg.norm(cv_img[16] - cv_img[45]),np.linalg.norm(cv_img[17] - cv_img[18]),np.linalg.norm(cv_img[17] - cv_img[36]),np.linalg.norm(cv_img[18] - cv_img[19]),     #40
                          np.linalg.norm(cv_img[18] - cv_img[37]),np.linalg.norm(cv_img[19] - cv_img[20]),np.linalg.norm(cv_img[19] - cv_img[37]),np.linalg.norm(cv_img[20] - cv_img[21]),np.linalg.norm(cv_img[20] - cv_img[38]),np.linalg.norm(cv_img[21] - cv_img[22]),np.linalg.norm(cv_img[21] - cv_img[27]),np.linalg.norm(cv_img[21] - cv_img[39]),np.linalg.norm(cv_img[22] - cv_img[23]),np.linalg.norm(cv_img[22] - cv_img[27]),     #50
                          np.linalg.norm(cv_img[22] - cv_img[42]),np.linalg.norm(cv_img[23] - cv_img[24]),np.linalg.norm(cv_img[23] - cv_img[43]),np.linalg.norm(cv_img[24] - cv_img[25]),np.linalg.norm(cv_img[24] - cv_img[44]),np.linalg.norm(cv_img[25] - cv_img[26]),np.linalg.norm(cv_img[25] - cv_img[44]),np.linalg.norm(cv_img[26] - cv_img[45]),np.linalg.norm(cv_img[27] - cv_img[39]),np.linalg.norm(cv_img[27] - cv_img[42]),     #60
                          np.linalg.norm(cv_img[28] - cv_img[29]),np.linalg.norm(cv_img[28] - cv_img[39]),np.linalg.norm(cv_img[28] - cv_img[42]),np.linalg.norm(cv_img[29] - cv_img[30]),np.linalg.norm(cv_img[29] - cv_img[39]),np.linalg.norm(cv_img[29] - cv_img[42]),np.linalg.norm(cv_img[30] - cv_img[31]),np.linalg.norm(cv_img[30] - cv_img[35]),np.linalg.norm(cv_img[31] - cv_img[32]),np.linalg.norm(cv_img[31] - cv_img[39]),     #70
                          np.linalg.norm(cv_img[31] - cv_img[40]),np.linalg.norm(cv_img[31] - cv_img[49]),np.linalg.norm(cv_img[32] - cv_img[33]),np.linalg.norm(cv_img[33] - cv_img[34]),np.linalg.norm(cv_img[33] - cv_img[51]),np.linalg.norm(cv_img[34] - cv_img[35]),np.linalg.norm(cv_img[35] - cv_img[42]),np.linalg.norm(cv_img[35] - cv_img[47]),np.linalg.norm(cv_img[35] - cv_img[53]),np.linalg.norm(cv_img[36] - cv_img[37]),     #80
                          np.linalg.norm(cv_img[37] - cv_img[38]),np.linalg.norm(cv_img[38] - cv_img[39]),np.linalg.norm(cv_img[39] - cv_img[40]),np.linalg.norm(cv_img[40] - cv_img[41]),np.linalg.norm(cv_img[41] - cv_img[46]),np.linalg.norm(cv_img[42] - cv_img[43]),np.linalg.norm(cv_img[43] - cv_img[44]),np.linalg.norm(cv_img[44] - cv_img[45]),np.linalg.norm(cv_img[45] - cv_img[46]),np.linalg.norm(cv_img[46] - cv_img[47]),     #90
                          np.linalg.norm(cv_img[47] - cv_img[42]),np.linalg.norm(cv_img[48] - cv_img[49]),np.linalg.norm(cv_img[48] - cv_img[59]),np.linalg.norm(cv_img[48] - cv_img[60]),np.linalg.norm(cv_img[49] - cv_img[50]),np.linalg.norm(cv_img[50] - cv_img[51]),np.linalg.norm(cv_img[50] - cv_img[62]),np.linalg.norm(cv_img[51] - cv_img[52]),np.linalg.norm(cv_img[52] - cv_img[53]),np.linalg.norm(cv_img[52] - cv_img[62]),     #100
                          np.linalg.norm(cv_img[53] - cv_img[64]),np.linalg.norm(cv_img[54] - cv_img[64]),np.linalg.norm(cv_img[55] - cv_img[56]),np.linalg.norm(cv_img[55] - cv_img[64]),np.linalg.norm(cv_img[56] - cv_img[57]),np.linalg.norm(cv_img[56] - cv_img[66]),np.linalg.norm(cv_img[57] - cv_img[58]),np.linalg.norm(cv_img[58] - cv_img[59]),np.linalg.norm(cv_img[58] - cv_img[66]),np.linalg.norm(cv_img[60] - cv_img[61]),     #110
                          np.linalg.norm(cv_img[60] - cv_img[67]),np.linalg.norm(cv_img[61] - cv_img[62]),np.linalg.norm(cv_img[61] - cv_img[67]),np.linalg.norm(cv_img[62] - cv_img[63]),np.linalg.norm(cv_img[63] - cv_img[64]),np.linalg.norm(cv_img[63] - cv_img[65]),np.linalg.norm(cv_img[64] - cv_img[65]),np.linalg.norm(cv_img[65] - cv_img[66]),np.linalg.norm(cv_img[66] - cv_img[67])]                                            #119
    if (image): 
      res=cv2.resize(img,(400,400))
      cv2_imshow(res)
    return dist_array
  else:
    print('*** NO SE PUDO ESTABLECER LANDMARKS PARA EL ARCHIVO "' + str(data) + '" ***')
    return cv_img

"""**Construcción de DATASET**"""

# Función para añadir imagen al dataset CSV

def img_to_csv(data, edad, sexo):
  ress = "1"
  for x in data:
    ress+=","
    ress+= str(x)
  ress+=","
  ress+=str(sexo)
  ress+=","
  ress+=str(edad)
  return(ress)

DS = pd.read_csv('/content/drive/My Drive/MACHINE LEARNING/dataset caras/csv_caras.csv')

# DATASET ENTRADAS

aux1 = []
for fila in DS.iterrows():
  aux  = []
  for i in range(1,120):
    aux.append(np.asarray(fila)[1][i])
  aux1.append(aux)

# DATASET SALIDAS GÉNERO

aux2= []
for fila in DS.iterrows():
  aux  = []
  aux2.append(np.asarray(fila)[1][120].astype(np.uint8))

# DATASET SALIDAS EDAD

aux3= []
for fila in DS.iterrows():
  aux  = []
  aux3.append(np.asarray(fila)[1][121].astype(np.uint8))

x_train        = np.array(aux1) # Array con vectores de rostros
y_gender_train = np.array(aux2) # Array salidas masculino/femenino (binary)
y_age_train    = np.array(aux3) # Array salidas edad (categorical)

y_gender_train = np_utils.to_categorical(y_gender_train)
y_age_train    = np_utils.to_categorical(y_age_train)

"""**Construcción de red**





"""

gender_net = Sequential()
gender_net.add(Dense(gender_netn[1], input_dim=gender_netn[0], activation='sigmoid'))
for x in age_netn[2:-1]:
  gender_net.add(Dense(x, activation='sigmoid'))
gender_net.add(Dense(len(y_gender_train[0]), activation='softmax'))

opt_gender = Adam(lr=lr_gender)

# # ENTRENAMIENTO DE RED GENERO
  # Ajustes de modelo de entrenamiento
  
x_gender_train, x_gender_valid, y_gender_train, y_gender_valid = train_test_split(x_train, y_gender_train, test_size=0.3)

# gender_net  = load_model('/content/drive/My Drive/MACHINE LEARNING/dataset caras/red_genero.h5')

gender_net.compile(loss='binary_crossentropy', optimizer=opt_gender, metrics=['accuracy'])
gender = gender_net.fit(x_gender_train, y_gender_train, epochs=epoch_gender,batch_size=batch_gender)

gender_net.save("/content/drive/My Drive/MACHINE LEARNING/dataset caras/red_genero1.h5")
print("******* RED GÉNERO GUARDADA *******")

age_net = Sequential()
age_net.add(Dense(age_netn[1], input_dim=age_netn[0], activation='sigmoid'))
for i in gender_netn[2:-1]:
  age_net.add(Dense(i, activation='sigmoid'))
age_net.add(Dense(len(y_age_train[0]), activation='softmax'))

opt_age = Adam(lr=lr_age)

# ENTRENAMIENTO DE RED EDAD
#   Ajustes de modelo de entrenamiento

x_age_train, x_age_valid, y_age_train, y_age_valid = train_test_split(x_train, y_age_train, test_size=0.3)

# age_net   = load_model('/content/drive/My Drive/MACHINE LEARNING/dataset caras/red_edad2.h5')

age_net.compile(loss='categorical_crossentropy', optimizer=opt_age, metrics=['accuracy'])

age = age_net.fit(x_age_train, y_age_train, epochs=epoch_age,batch_size=batch_age)

age_net.save("/content/drive/My Drive/MACHINE LEARNING/dataset caras/red_edad1.h5")
print("******* RED EDAD GUARDADA *******")

# VISUALIZACIÓN DE ENTRENAMIENTO GENERO

plt.figure()
epoch_values = list(range(epoch_gender))
plt.plot(epoch_values, gender.history['accuracy'], label='Evolución precisión GÉNERO',c='b')
 
plt.title('Exactitud de Entrenamiento')
plt.xlabel('Época')
plt.ylabel('Precisión')
plt.legend()

# VISUALIZACIÓN DE ENTRENAMIENTO EDAD 

plt.figure()
epoch_values = list(range(epoch_age))
plt.plot(epoch_values, age.history['accuracy'], label='Evolución precisión EDAD',c='r')
 
plt.title('Exactitud de Entrenamiento')
plt.xlabel('Época')
plt.ylabel('Precisión')
plt.legend()

"""**Prueba de modelos**"""

# Carga de modelos entrenados
red_genero = load_model('/content/drive/My Drive/MACHINE LEARNING/dataset caras/red_genero1.h5')
red_edad   = load_model('/content/drive/My Drive/MACHINE LEARNING/dataset caras/red_edad1.h5')

test = read_data('/content/drive/My Drive/MACHINE LEARNING/dataset caras/Imagen cara/test11.JPG',1)

if red_genero.predict(np.array([test]))[0][0] > red_genero.predict(np.array([test]))[0][1]:
  aux = str("HOMBRE ---- Precisión: "+str(round(red_genero.predict(np.array([test]))[0][0]*100,5))+" %")
else:
  aux = str("MUJER ----- Precisión: "+str(round(red_genero.predict(np.array([test]))[0][1]*100,5))+" %")

res_edad = np.where(red_edad.predict(np.array([test])) == np.amax(red_edad.predict(np.array([test]))))

print("Sexo         :", aux)
print("Edad estimada:", res_edad[1][0], "    ---- Precisión:", str(round(np.amax(red_edad.predict(np.array([test])))*100,5)),"%")

img_to_csv(test,70.0,1.0)

plt.figure()
epoch_values = list(range(len(list(red_edad.predict(np.array([test]))[0]))))
plt.plot(epoch_values, list(red_edad.predict(np.array([test]))[0]), label='Evolución precisión EDAD',c='r')
 
plt.title('Exactitud de Entrenamiento')
plt.xlabel('Época')
plt.ylabel('Precisión')
plt.legend()
